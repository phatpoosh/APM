{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA 3 PARTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "12731f025a5d8cc37a6e68aa01458d376993c56a"
   },
   "source": [
    "# PART 1: Recovering the Videos\n",
    "In this notebook we will show how to view the videos contained in the [CVPR 2018 WAD Video Segmentation Challenge](https://www.kaggle.com/c/cvpr-2018-autonomous-driving) dataset. \n",
    "### Sources and Resources \n",
    "* http://tiao.io/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/\n",
    "* https://matplotlib.org/gallery/animation/dynamic_image2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skimage.io import imread \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_names = os.listdir(\"/Users/quinn/Desktop/AdvPredictiveModeling/GroupProject/input/train_label_camera5\") \n",
    "trainingImgNameDF = pd.DataFrame( list(map(lambda s : [s]+s.split(\"_\") , training_img_names )) ).drop(3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170908_061536323_Camera_5_instanceIds.png</td>\n",
       "      <td>170908</td>\n",
       "      <td>061536323</td>\n",
       "      <td>5</td>\n",
       "      <td>instanceIds.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170908_061534933_Camera_5_instanceIds.png</td>\n",
       "      <td>170908</td>\n",
       "      <td>061534933</td>\n",
       "      <td>5</td>\n",
       "      <td>instanceIds.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170908_061518393_Camera_5_instanceIds.png</td>\n",
       "      <td>170908</td>\n",
       "      <td>061518393</td>\n",
       "      <td>5</td>\n",
       "      <td>instanceIds.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170908_061519366_Camera_5_instanceIds.png</td>\n",
       "      <td>170908</td>\n",
       "      <td>061519366</td>\n",
       "      <td>5</td>\n",
       "      <td>instanceIds.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170908_061531041_Camera_5_instanceIds.png</td>\n",
       "      <td>170908</td>\n",
       "      <td>061531041</td>\n",
       "      <td>5</td>\n",
       "      <td>instanceIds.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0       1          2  4  \\\n",
       "0  170908_061536323_Camera_5_instanceIds.png  170908  061536323  5   \n",
       "1  170908_061534933_Camera_5_instanceIds.png  170908  061534933  5   \n",
       "2  170908_061518393_Camera_5_instanceIds.png  170908  061518393  5   \n",
       "3  170908_061519366_Camera_5_instanceIds.png  170908  061519366  5   \n",
       "4  170908_061531041_Camera_5_instanceIds.png  170908  061531041  5   \n",
       "\n",
       "                 5  \n",
       "0  instanceIds.png  \n",
       "1  instanceIds.png  \n",
       "2  instanceIds.png  \n",
       "3  instanceIds.png  \n",
       "4  instanceIds.png  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingImgNameDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_names2 = os.listdir(\"/Users/quinn/Desktop/AdvPredictiveModeling/GroupProject/input/train_color_camera5/\") \n",
    "trainingImgNameDF2 = pd.DataFrame( list(map(lambda s : [s]+s.split(\"_\") , training_img_names2 )) ).drop(3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170908_061504215_Camera_5.jpg</td>\n",
       "      <td>170908</td>\n",
       "      <td>061504215</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170908_061523674_Camera_5.jpg</td>\n",
       "      <td>170908</td>\n",
       "      <td>061523674</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170908_061533404_Camera_5.jpg</td>\n",
       "      <td>170908</td>\n",
       "      <td>061533404</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170908_061527288_Camera_5.jpg</td>\n",
       "      <td>170908</td>\n",
       "      <td>061527288</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170908_061526176_Camera_5.jpg</td>\n",
       "      <td>170908</td>\n",
       "      <td>061526176</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0       1          2      4\n",
       "0  170908_061504215_Camera_5.jpg  170908  061504215  5.jpg\n",
       "1  170908_061523674_Camera_5.jpg  170908  061523674  5.jpg\n",
       "2  170908_061533404_Camera_5.jpg  170908  061533404  5.jpg\n",
       "3  170908_061527288_Camera_5.jpg  170908  061527288  5.jpg\n",
       "4  170908_061526176_Camera_5.jpg  170908  061526176  5.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingImgNameDF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "9876c47c-4405-49ba-99e8-67f161afb9e7",
    "_uuid": "5c40543b6bca827774a6cf995c39aa223b2b9247"
   },
   "outputs": [],
   "source": [
    "# define a function to convert images to video\n",
    "def visVid(trainingImgNameDF,sessionID,cameraID,startFrame=0,endFrame=10,\n",
    "           dataRoot=\"/Users/quinn/Desktop/AdvPredictiveModeling/GroupProject/input/train_label_camera5/\"):\n",
    "    res = trainingImgNameDF[ (trainingImgNameDF[1] == sessionID) & \n",
    "                            (trainingImgNameDF[4] == cameraID)].sort_values(by=2)\n",
    "    imgURIs = list(res[0])\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    frames = []\n",
    "    for uri in imgURIs[startFrame:endFrame]:\n",
    "        im = plt.imshow( imread(dataRoot+uri), animated=True)\n",
    "        frames.append([im])\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return animation.ArtistAnimation(fig,frames,interval=500, blit=True,repeat_delay=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define a function to convert images to video\n",
    "def visVid2(trainingImgNameDF,sessionID,cameraID,startFrame=0,endFrame=10,\n",
    "           dataRoot=\"/Users/quinn/Desktop/AdvPredictiveModeling/GroupProject/input/train_color_camera5/\"):\n",
    "    res = trainingImgNameDF[ (trainingImgNameDF[1] == sessionID) & \n",
    "                            (trainingImgNameDF[4] == cameraID)].sort_values(by=2)\n",
    "    imgURIs = list(res[0])\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    frames = []\n",
    "    for uri in imgURIs[startFrame:endFrame]:\n",
    "        im = plt.imshow( imread(dataRoot+uri), animated=True)\n",
    "        frames.append([im])\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return animation.ArtistAnimation(fig,frames,interval=500, blit=True,repeat_delay=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "fb2d8647-0da6-478a-9e5a-e41a53788371",
    "_uuid": "4fb0ff383571c1fad07b03b1053403c18167b4c8"
   },
   "outputs": [],
   "source": [
    "# create a video of label images\n",
    "uniqueVideoID = trainingImgNameDF[1].unique()\n",
    "ani = visVid(trainingImgNameDF,uniqueVideoID[0],\"5\")\n",
    "ani.save('camera5label.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "30b5af6a-617d-4356-aae0-649e25722afd",
    "_uuid": "3cbfd04e7acf3c6f03521cec48c1429af8967a4e"
   },
   "outputs": [],
   "source": [
    "# create a video of colored images\n",
    "uniqueVideoID2 = trainingImgNameDF2[1].unique()\n",
    "ani = visVid2(trainingImgNameDF2,uniqueVideoID2[0],\"5.jpg\")\n",
    "ani.save('camera5colored.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: First Look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we would like to see what the training images look like and what we are suppose to detect. Using scikit-image segmentation module, dask.array.image, and matplotlib, we were able to display the original image, the colored labels, and the cropped overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "USE_CV2 = True\n",
    "if USE_CV2:\n",
    "    from cv2 import imread # opencv is much faster, but less accurate\n",
    "    MIN_OBJ_VAL = 0\n",
    "else:\n",
    "    from skimage.io import imread\n",
    "    MIN_OBJ_VAL = 1000\n",
    "\n",
    "from skimage.segmentation import mark_boundaries\n",
    "DATA_DIR = os.path.join('..', 'input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = pd.DataFrame(dict(path = glob(os.path.join(DATA_DIR, '*', '*.*p*g'))))\n",
    "all_paths['split'] = all_paths['path'].map(lambda x: x.split('/')[-2].split('_')[0])\n",
    "all_paths['group'] = all_paths['path'].map(lambda x: x.split('/')[-2].split('_')[-1])\n",
    "all_paths['group'] = all_paths['group'].map(lambda x: 'color' if x == 'test' else x)\n",
    "all_paths['id'] = all_paths['path'].map(lambda x: '_'.join(os.path.splitext(os.path.basename(x))[0].split('_')[:4]))\n",
    "all_paths.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = all_paths.pivot_table(values = 'path', columns = 'group', aggfunc = 'first', index = ['id', 'split']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we would like to see what the training images look like and what we are suppose to detect. Using scikit-image segmentation module, dask.array.image, and matplotlib, we were able to display the original image, the colored labels, and the cropped overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = group_df.query('split==\"train\"')\n",
    "print(train_df.shape[0], 'rows')\n",
    "sample_rows = 6\n",
    "fig, m_axs = plt.subplots(sample_rows, 3, figsize = (20, 6*sample_rows))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "for (ax1, ax2, ax3), (_, c_row) in zip(m_axs, train_df.sample(sample_rows).iterrows()):\n",
    "    c_img = imread(c_row['color'])\n",
    "    l_img = imread(c_row['label'])\n",
    "    if l_img.ndim==3: l_img = l_img[:,:,0]\n",
    "    ax1.imshow(c_img)\n",
    "    ax1.set_title('Color')\n",
    "    # make the labels nicer\n",
    "    nice_limg = np.zeros(l_img.shape, dtype = np.uint8)\n",
    "    for new_idx, old_idx in enumerate(np.unique(l_img[l_img>MIN_OBJ_VAL]), 1):\n",
    "        nice_limg[l_img==old_idx]=new_idx\n",
    "    ax2.imshow(nice_limg, cmap = 'nipy_spectral')\n",
    "    ax2.set_title('Labels')\n",
    "    xd, yd = np.where(l_img>MIN_OBJ_VAL)\n",
    "    bound_img = mark_boundaries(image = c_img, label_img = l_img, color = (1,0,0), background_label = 255, mode = 'thick')\n",
    "    ax3.imshow(bound_img[xd.min():xd.max(), yd.min():yd.max(),:])\n",
    "    ax3.set_title('Cropped Overlay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dask.array.image import imread\n",
    "from dask import bag, threaded\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filecheck(dir):\n",
    "    dir_size = 0\n",
    "    filelist = os.listdir(dir)\n",
    "    filelist.sort()\n",
    "    print(dir)\n",
    "    for i,name in enumerate(filelist):\n",
    "        dir_size += os.path.getsize(os.path.join(dir, name))\n",
    "    print(\"{:.1f} GB of {} files\".format(dir_size/1024/1024/1024, i))\n",
    "    print(\"showing sample files\")\n",
    "    print(\"\\n\".join(filelist[300:306]) + \"\\n\")\n",
    "\n",
    "dirs = [\"../input/train_color\",\"../input/train_label\", \"../input/test\"]\n",
    "\n",
    "for d in dirs[0:2]:\n",
    "    filecheck(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask imread version - in progress\n",
    "def divmil():\n",
    "    return 1\n",
    "# labels is the image array\n",
    "labels = imread(\"../input/train_label/*.png\")\n",
    "print(labels.shape, labels[0].shape, divmil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(dirs[1])\n",
    "fullpaths = [\"../input/train_label/\" + f for f in filenames]\n",
    "\n",
    "# set up a bag\n",
    "def get_ims(impath):\n",
    "    tlabel = io.imread(impath, plugin='pil')\n",
    "    cls = np.unique(tlabel)\n",
    "    unique,counts = np.unique(cls//1000, return_counts=True)\n",
    "    ds = dict(zip(unique, counts))\n",
    "    return ds\n",
    "\n",
    "labelbag = bag.from_sequence(fullpaths).map(get_ims)\n",
    "with ProgressBar():\n",
    "    labels = labelbag.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first created a dataframe called label_df, which contains the label file name and number of interested classes in each training label image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame(labels, index=filenames, dtype='uint8')\n",
    "labels_df.fillna(value=0, inplace=True)\n",
    "labels_df = labels_df.astype(int)\n",
    "labels_df.rename(columns=classdict, inplace=True)      \n",
    "labels_df.drop(columns=['others', 'rider', 'traffic_cone'], inplace=True)\n",
    "\n",
    "labels_df.to_csv('train_labels.csv')\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes_df = pd.melt(labels_df)\n",
    "groups = classes_df.groupby('variable')\n",
    "sums = groups.sum()\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "ax = sns.barplot(x=sums.index, y=sums.value, color='steelblue')\n",
    "ax.set(xlabel='', ylabel='count')\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data frame above, we created few histograms using seaborn library. \n",
    "\n",
    "Class Frequencies: We found that cars and person are the two most frequently appeared classes in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.melt(labels_df)\n",
    "groups = classes_df.groupby('variable')\n",
    "sums = groups.sum()\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "ax = sns.barplot(x=sums.index, y=sums.value, color='steelblue')\n",
    "ax.set(xlabel='', ylabel='count')\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['objects'] = labels_df.sum(axis=1)\n",
    "labels_df['classes'] = labels_df[labels_df>0].count(axis=1)-1\n",
    "labels_df.clip(lower=0, inplace=True)   # crude fix for when no objects are seen\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.title(\"Total Number of Objects\")\n",
    "labels_df['objects'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Distinct Classes per Image: The majority of images have two to four distinct classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.title(\"Number of Distinct Classes\")\n",
    "labels_df['classes'].value_counts().sort_index().plot.bar(color='steelblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Cars per Image: Majority of the images have 0~10 cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.title(\"Number of Cars per Image\")\n",
    "labels_df['car'].value_counts().sort_index().plot.bar(color='steelblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Person per Image: Most of the images have 0~5 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.title(\"Number of People per Image\")\n",
    "labels_df['person'].value_counts().sort_index().plot.bar(color='steelblue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
